"""
ë©”ì¸ í¬ë¡¤ëŸ¬ í†µí•© í…ŒìŠ¤íŠ¸
"""
import pytest
import asyncio
import tempfile
from pathlib import Path
from unittest.mock import Mock, patch, AsyncMock
from main_crawler import MainCrawler

class TestMainCrawler:
    """ë©”ì¸ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def setup_method(self):
        """ê° í…ŒìŠ¤íŠ¸ ë©”ì†Œë“œ ì‹¤í–‰ ì „ ì„¤ì •"""
        self.temp_dir = tempfile.mkdtemp()
        self.excel_path = str(Path(self.temp_dir) / "test_excel.xlsx")
        self.output_file = str(Path(self.temp_dir) / "test_output.json")
        
        self.main_crawler = MainCrawler(
            excel_path=self.excel_path,
            max_concurrent=2,
            delay_range=(0.1, 0.2),
            output_file=self.output_file
        )
    
    def teardown_method(self):
        """ê° í…ŒìŠ¤íŠ¸ ë©”ì†Œë“œ ì‹¤í–‰ í›„ ì •ë¦¬"""
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_init(self):
        """ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        assert self.main_crawler.excel_path == self.excel_path
        assert self.main_crawler.max_concurrent == 2
        assert self.main_crawler.delay_range == (0.1, 0.2)
        assert self.main_crawler.output_file == self.output_file
        assert self.main_crawler.excel_processor is not None
        assert self.main_crawler.crawler is not None
    
    @pytest.mark.asyncio
    async def test_run_with_progress_success(self):
        """ì§„í–‰ë¥  í‘œì‹œì™€ í•¨ê»˜ í¬ë¡¤ë§ ì„±ê³µ í…ŒìŠ¤íŠ¸"""
        test_product_ids = ['A123456', 'A789012', 'A345678']
        
        # Excel ì²˜ë¦¬ê¸° Mock
        mock_excel_process = Mock(return_value=test_product_ids)
        self.main_crawler.excel_processor.process = mock_excel_process
        
        # í¬ë¡¤ëŸ¬ Mock
        mock_crawler_result = {
            'stats': {
                'total': 3,
                'success': 3,
                'failed': 0
            },
            'total_time': 10.0,
            'results': [
                {'product_id': 'A123456', 'title': 'Product 1'},
                {'product_id': 'A789012', 'title': 'Product 2'},
                {'product_id': 'A345678', 'title': 'Product 3'}
            ]
        }
        
        with patch.object(self.main_crawler.crawler, 'crawl_products', return_value=mock_crawler_result):
            with patch('main_crawler.tqdm') as mock_tqdm:
                with patch('time.time', side_effect=[1000.0, 1010.0]):  # ì‹œì‘ ì‹œê°„, ì¢…ë£Œ ì‹œê°„
                    with patch('main_crawler.logger') as mock_logger:
                        result = await self.main_crawler.run_with_progress()
        
        assert result == mock_crawler_result
        mock_excel_process.assert_called_once()
        mock_logger.info.assert_any_call("ğŸ¯ ì˜¬ë¦¬ë¸Œì˜ ìƒí’ˆ í¬ë¡¤ë§ ì‹œì‘")
        mock_logger.info.assert_any_call("ğŸ† í¬ë¡¤ë§ ì‘ì—… ì™„ë£Œ!")
    
    @pytest.mark.asyncio
    async def test_run_with_progress_excel_failure(self):
        """Excel ì²˜ë¦¬ ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸"""
        # Excel ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜
        mock_excel_process = Mock(return_value=None)
        self.main_crawler.excel_processor.process = mock_excel_process
        
        with patch('main_crawler.logger') as mock_logger:
            result = await self.main_crawler.run_with_progress()
        
        assert result is None
        mock_excel_process.assert_called_once()
        mock_logger.error.assert_called_with("âŒ Excelì—ì„œ ìœ íš¨í•œ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    @pytest.mark.asyncio
    async def test_run_with_progress_empty_ids(self):
        """ë¹ˆ ID ëª©ë¡ í…ŒìŠ¤íŠ¸"""
        # ë¹ˆ ID ëª©ë¡ ë°˜í™˜
        mock_excel_process = Mock(return_value=[])
        self.main_crawler.excel_processor.process = mock_excel_process
        
        with patch('main_crawler.logger') as mock_logger:
            result = await self.main_crawler.run_with_progress()
        
        assert result is None
        mock_logger.error.assert_called_with("âŒ Excelì—ì„œ ìœ íš¨í•œ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    def test_run_sync_wrapper(self):
        """ë™ê¸° ì‹¤í–‰ ë˜í¼ í…ŒìŠ¤íŠ¸"""
        mock_result = {'test': 'result'}
        
        with patch.object(self.main_crawler, 'run_with_progress', return_value=mock_result) as mock_run:
            with patch('asyncio.run') as mock_asyncio_run:
                mock_asyncio_run.return_value = mock_result
                
                result = self.main_crawler.run()
        
        mock_asyncio_run.assert_called_once()
        assert result == mock_result
    
    def test_default_configuration(self):
        """ê¸°ë³¸ ì„¤ì • í…ŒìŠ¤íŠ¸"""
        default_crawler = MainCrawler()
        
        assert default_crawler.excel_path == "data/Qoo10_ItemInfo.xlsx"
        assert default_crawler.max_concurrent == 3
        assert default_crawler.delay_range == (1, 3)
        assert default_crawler.output_file == "olive_young_products.json"
    
    @pytest.mark.asyncio
    async def test_progress_bar_interaction(self):
        """ì§„í–‰ë¥  í‘œì‹œì¤„ ìƒí˜¸ì‘ìš© í…ŒìŠ¤íŠ¸"""
        test_product_ids = ['A123456', 'A789012']
        
        # Excel ì²˜ë¦¬ê¸° Mock
        self.main_crawler.excel_processor.process = Mock(return_value=test_product_ids)
        
        # Mock tqdm ì§„í–‰ë¥  í‘œì‹œì¤„
        mock_progress_bar = Mock()
        
        # í¬ë¡¤ëŸ¬ Mock (ê° ìƒí’ˆë³„ë¡œ í˜¸ì¶œë˜ëŠ” í•¨ìˆ˜)
        original_crawl = AsyncMock()
        original_crawl.side_effect = [
            {'product_id': 'A123456', 'title': 'Product 1'},
            {'product_id': 'A789012', 'title': 'Product 2'}
        ]
        
        # í¬ë¡¤ëŸ¬ ê²°ê³¼ Mock
        mock_crawler_result = {
            'stats': {'total': 2, 'success': 2, 'failed': 0},
            'total_time': 5.0,
            'results': []
        }
        
        with patch('main_crawler.tqdm', return_value=mock_progress_bar):
            with patch.object(self.main_crawler.crawler, 'crawl_products', return_value=mock_crawler_result):
                with patch('time.time', side_effect=[1000.0, 1005.0]):
                    with patch('main_crawler.logger'):
                        result = await self.main_crawler.run_with_progress()
        
        # ì§„í–‰ë¥  í‘œì‹œì¤„ì´ ì ì ˆíˆ ì‚¬ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸
        mock_progress_bar.close.assert_called_once()
        assert result == mock_crawler_result
    
    @pytest.mark.asyncio
    async def test_statistics_calculation(self):
        """í†µê³„ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        test_product_ids = ['A123456'] * 100  # 100ê°œ ìƒí’ˆ
        
        self.main_crawler.excel_processor.process = Mock(return_value=test_product_ids)
        
        mock_crawler_result = {
            'stats': {
                'total': 100,
                'success': 85,
                'failed': 10
            },
            'total_time': 60.0,  # 1ë¶„
            'results': []
        }
        
        with patch.object(self.main_crawler.crawler, 'crawl_products', return_value=mock_crawler_result):
            with patch('main_crawler.tqdm') as mock_tqdm:
                with patch('time.time', side_effect=[1000.0, 1060.0]):  # 60ì´ˆ ê²½ê³¼
                    with patch('main_crawler.logger') as mock_logger:
                        result = await self.main_crawler.run_with_progress()
        
        # ë¡œê·¸ì—ì„œ í†µê³„ ì •ë³´ í™•ì¸
        log_calls = mock_logger.info.call_args_list
        log_messages = [call[0][0] for call in log_calls]
        
        # ì„±ê³µë¥  ê³„ì‚° í™•ì¸ (85/100 = 85%)
        success_rate_log = next((msg for msg in log_messages if "85.0%" in msg), None)
        assert success_rate_log is not None
        
        # ì²˜ë¦¬ ì†ë„ í™•ì¸ (100ê°œ/60ì´ˆ â‰ˆ 1.67 ìƒí’ˆ/ì´ˆ)
        processing_speed_log = next((msg for msg in log_messages if "ìƒí’ˆ/ì´ˆ" in msg), None)
        assert processing_speed_log is not None
    
    def test_configuration_validation(self):
        """ì„¤ì • ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        # ì˜ëª»ëœ max_concurrent ê°’ í…ŒìŠ¤íŠ¸
        crawler1 = MainCrawler(max_concurrent=0)
        assert crawler1.max_concurrent == 0  # ì‹¤ì œë¡œëŠ” ê²€ì¦ ë¡œì§ì´ ìˆì–´ì•¼ í•¨
        
        # ì˜ëª»ëœ delay_range ê°’ í…ŒìŠ¤íŠ¸
        crawler2 = MainCrawler(delay_range=(5, 1))  # max < min
        assert crawler2.delay_range == (5, 1)  # ì‹¤ì œë¡œëŠ” ê²€ì¦ ë¡œì§ì´ ìˆì–´ì•¼ í•¨
    
    @pytest.mark.parametrize("concurrent,delay_range,expected_time_range", [
        (1, (1, 2), (50, 200)),  # ëŠë¦° ì„¤ì •
        (5, (0.1, 0.5), (5, 30)),  # ë¹ ë¥¸ ì„¤ì •
        (3, (1, 3), (20, 100)),   # ë³´í†µ ì„¤ì •
    ])
    @pytest.mark.asyncio
    async def test_estimated_time_calculation(self, concurrent, delay_range, expected_time_range):
        """ì˜ˆìƒ ì‹œê°„ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        test_product_ids = ['A123456'] * 50  # 50ê°œ ìƒí’ˆ
        
        crawler = MainCrawler(
            max_concurrent=concurrent,
            delay_range=delay_range,
            excel_path=self.excel_path,
            output_file=self.output_file
        )
        crawler.excel_processor.process = Mock(return_value=test_product_ids)
        
        mock_crawler_result = {
            'stats': {'total': 50, 'success': 50, 'failed': 0},
            'total_time': 30.0,
            'results': []
        }
        
        with patch.object(crawler.crawler, 'crawl_products', return_value=mock_crawler_result):
            with patch('main_crawler.tqdm'):
                with patch('time.time', side_effect=[1000.0, 1030.0]):
                    with patch('main_crawler.logger') as mock_logger:
                        await crawler.run_with_progress()
        
        # ì˜ˆìƒ ì‹œê°„ì´ ë¡œê·¸ì— ê¸°ë¡ë˜ì—ˆëŠ”ì§€ í™•ì¸
        log_calls = mock_logger.info.call_args_list
        estimated_time_log = next((call for call in log_calls if "ì˜ˆìƒ ì†Œìš” ì‹œê°„" in call[0][0]), None)
        assert estimated_time_log is not None