"""
ì˜¬ë¦¬ë¸Œì˜ ìƒí’ˆ í¬ë¡¤ëŸ¬
CloudFlare Challenge ìš°íšŒ ê¸°ëŠ¥ í¬í•¨
"""
import asyncio
import logging
import json
import time
import random
from typing import Dict, List, Optional
from pathlib import Path
from playwright.async_api import async_playwright, Browser, Page, BrowserContext
from asyncio_throttle import Throttler
import aiofiles

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class OliveYoungCrawler:
    def __init__(self, 
                 max_concurrent: int = 3,
                 delay_range: tuple = (1, 3),
                 output_file: str = "crawled_data.json",
                 progress_file: str = "crawling_progress.json"):
        """
        ì˜¬ë¦¬ë¸Œì˜ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
        
        Args:
            max_concurrent: ìµœëŒ€ ë™ì‹œ ì‹¤í–‰ ìˆ˜
            delay_range: ìš”ì²­ ê°„ ë”œë ˆì´ ë²”ìœ„ (ì´ˆ)
            output_file: ê²°ê³¼ ì €ì¥ íŒŒì¼ëª…
            progress_file: ì§„í–‰ ìƒí™© ì €ì¥ íŒŒì¼ëª…
        """
        self.max_concurrent = max_concurrent
        self.delay_range = delay_range
        self.output_file = output_file
        self.progress_file = progress_file
        self.base_url = "https://www.oliveyoung.co.kr/store/goods/getGoodsDetail.do"
        
        # í†µê³„ ì¶”ì 
        self.stats = {
            'total': 0,
            'success': 0,
            'failed': 0,
        }
        
        # ì¤‘ë‹¨ í”Œë˜ê·¸
        self.user_interrupted = False
        
        # ê²°ê³¼ ì €ì¥ìš©
        self.results = []
        
        # Throttler ì„¤ì • (ë™ì‹œ ìš”ì²­ ì œí•œ)
        self.throttler = Throttler(rate_limit=max_concurrent, period=1.0)
        

    
    async def create_browser_context(self, browser: Browser) -> BrowserContext:
        """CloudFlare ìš°íšŒë¥¼ ìœ„í•œ ë¸Œë¼ìš°ì € ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        logger.info("ğŸŒ ë¸Œë¼ìš°ì € ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì¤‘ (CloudFlare ìš°íšŒ ì„¤ì •)")
        
        # ëœë¤ User-Agent ëª©ë¡
        user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0"
        ]
        
        context = await browser.new_context(
            user_agent=random.choice(user_agents),
            viewport={'width': 1920, 'height': 1080},
            extra_http_headers={
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
                'Accept-Encoding': 'gzip, deflate',
                'DNT': '1',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
            }
        )
        
        # JavaScript í™œì„±í™” ë° ê¸°ë³¸ ì„¤ì •
        await context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined,
            });
        """)
        
        return context
    
    
    async def check_product_availability(self, context: BrowserContext, product_id: str) -> Optional[Dict]:
        """ìƒí’ˆ íŒë§¤ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        page = None
        try:
            async with self.throttler:
                page = await context.new_page()
                
                # ìš”ì²­ ê°„ ëœë¤ ë”œë ˆì´
                delay = random.uniform(*self.delay_range)
                await asyncio.sleep(delay)
                
                url = f"{self.base_url}?goodsNo={product_id}"
                
                start_time = time.time()
                logger.info(f"ğŸ” í¬ë¡¤ë§ ì‹œì‘: {product_id} ({url})")
                
                # í˜ì´ì§€ ë¡œë“œ (íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬) - domcontentloadedë¡œ ë³€ê²½í•˜ì—¬ ì†ë„ ê°œì„ 
                try:
                    response = await page.goto(url, wait_until='domcontentloaded', timeout=15000)  # 15ì´ˆ íƒ€ì„ì•„ì›ƒ
                    # í˜ì´ì§€ ì•ˆì •í™”ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
                    await asyncio.sleep(0.5)
                except Exception as e:
                    if 'timeout' in str(e).lower():
                        logger.warning(f"â° í˜ì´ì§€ ë¡œë“œ íƒ€ì„ì•„ì›ƒ (ID: {product_id}): {str(e)} - ë‹¤ìŒ ìƒí’ˆìœ¼ë¡œ ê³„ì†")
                        # íƒ€ì„ì•„ì›ƒì€ ê°œë³„ ìƒí’ˆ ë¬¸ì œì´ë¯€ë¡œ ì „ì²´ ì¤‘ë‹¨í•˜ì§€ ì•ŠìŒ
                        return {
                            'product_id': product_id,
                            'url': url,
                            'status': 'timeout',
                            'error': str(e),
                            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                            'crawl_time': time.time() - start_time
                        }
                    else:
                        raise e
                
                if not response:
                    logger.error(f"âŒ í˜ì´ì§€ ì‘ë‹µ ì—†ìŒ (ID: {product_id})")
                    return None
                
                logger.info(f"ğŸ“¡ HTTP ì‘ë‹µ ì½”ë“œ: {response.status} (ID: {product_id})")
                
                
                # í˜ì´ì§€ ì œëª© í™•ì¸
                title = await page.title()
                
                # ìƒí’ˆ ì •ë³´ ì¶”ì¶œ (ê¸°ë³¸ ì •ë³´ë§Œ)
                product_data = {
                    'product_id': product_id,
                    'url': url,
                    'title': title,
                    'status_code': response.status,
                    'crawl_time': time.time() - start_time,
                    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
                }
                
                # # ì¶”ê°€ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ì‹œë„
                # try:
                #     # ìƒí’ˆëª… ì¶”ì¶œ
                #     product_name = await page.query_selector('.prd_name')
                #     if product_name:
                #         product_data['product_name'] = await product_name.text_content()
                    
                #     # ê°€ê²© ì •ë³´ ì¶”ì¶œ
                #     price_element = await page.query_selector('.price')
                #     if price_element:
                #         product_data['price'] = await price_element.text_content()

                # ë¬¼í’ˆ ì •ìƒ íŒë§¤ ì—¬ë¶€ í™•ì¸
                try:
                    # ì²« ë²ˆì§¸ í™•ì¸: ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ì—ëŸ¬ í˜ì´ì§€
                    error_content = await page.query_selector('#error-contents.error-page.noProduct')
                    if error_content:
                        product_data['product_status'] = 'soldOut'
                        product_data['soldout_reason'] = 'product_not_found'
                    else:
                        # ë‘ ë²ˆì§¸ í™•ì¸: ë°”ë¡œêµ¬ë§¤ ë²„íŠ¼ì˜ display ìŠ¤íƒ€ì¼
                        buy_button = await page.query_selector('button.btnBuy.goods_buy#cartBtn')
                        if buy_button:
                            button_style = await buy_button.get_attribute('style')
                            if button_style and 'display: none' in button_style:
                                product_data['product_status'] = 'soldOut'
                                product_data['soldout_reason'] = 'button_hidden'
                            else:
                                product_data['product_status'] = 'saleOn'
                        else:
                            # ë²„íŠ¼ì´ ì—†ìœ¼ë©´ íŒë§¤ ì¢…ë£Œë¡œ ê°„ì£¼
                            product_data['product_status'] = 'soldOut'
                            product_data['soldout_reason'] = 'button_not_found'
                        
                except Exception as e:
                    logger.warning(f"âš ï¸  ìƒí’ˆ íŒë§¤ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨ (ID: {product_id}): {str(e)}")
                    product_data['product_status'] = 'unknown'
                
                logger.info(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {product_id} ({product_data['crawl_time']:.2f}ì´ˆ)")
                return product_data
                
        except Exception as e:
            logger.error(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨ (ID: {product_id}): {str(e)}")
            return None
            
        finally:
            if page:
                await page.close()
    
    async def save_results(self):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        try:
            logger.info(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘: {self.output_file}")
            
            output_data = {
                'metadata': {
                    'total_crawled': len(self.results),
                    'stats': self.stats,
                    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
                },
                'products': self.results
            }
            
            async with aiofiles.open(self.output_file, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(output_data, ensure_ascii=False, indent=2))
            
            logger.info(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {self.output_file}")
            
        except Exception as e:
            logger.error(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    async def save_progress(self, product_ids: List[str], processed_items: List[str], current_item: str = None):
        """ì§„í–‰ ìƒí™© ì €ì¥"""
        try:
            # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì•„ì´í…œì´ ìˆë‹¤ë©´ processed_itemsì— ì˜¬ë¦¬ì§€ ì•ŠìŒ
            processed_count = len(processed_items)
            remaining_items = []
            
            # ë¹„ì •ìƒ ì¤‘ë‹¨ì˜ ê²½ìš° í˜„ì¬ ì•„ì´í…œì„ ë‹¤ì‹œ ì²˜ë¦¬í•˜ë„ë¡ ë‚¨ê²¨ë‘˜ê¸°
            if current_item and current_item not in processed_items:
                # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì•„ì´í…œì„ remaining_items ë§¨ ì•ì— ì¶”ê°€
                remaining_items.append(current_item)
                
            # ë‚˜ë¨¸ì§€ ì•„ì§ ì²˜ë¦¬í•˜ì§€ ì•Šì€ ì•„ì´í…œë“¤ ì¶”ê°€
            for item in product_ids:
                if item not in processed_items and item != current_item:
                    remaining_items.append(item)
            
            progress_data = {
                'total_items': len(product_ids),
                'processed_count': processed_count,
                'processed_items': processed_items,
                'remaining_items': remaining_items,
                'current_item_rescued': current_item is not None,
                'stats': self.stats,
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            }
            
            async with aiofiles.open(self.progress_file, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(progress_data, ensure_ascii=False, indent=2))
                
        except Exception as e:
            logger.warning(f"âš ï¸  ì§„í–‰ ìƒí™© ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    async def load_progress(self) -> Optional[Dict]:
        """ì§„í–‰ ìƒí™© ë¶ˆëŸ¬ì˜¤ê¸°"""
        try:
            if Path(self.progress_file).exists():
                async with aiofiles.open(self.progress_file, 'r', encoding='utf-8') as f:
                    content = await f.read()
                    return json.loads(content)
            return None
        except Exception as e:
            logger.warning(f"âš ï¸  ì§„í–‰ ìƒí™© ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None
    
    async def crawl_products(self, product_ids: List[str], resume_from_progress: bool = True) -> Dict:
        """ë©”ì¸ í¬ë¡¤ë§ í•¨ìˆ˜"""
        
        # ì§„í–‰ ìƒí™©ì—ì„œ ì¬ì‹œì‘í•˜ëŠ” ê²½ìš°
        if resume_from_progress:
            progress = await self.load_progress()
            if progress:
                logger.info(f"ğŸ“‚ ì´ì „ ì§„í–‰ ìƒí™© ë°œê²¬: {progress['processed_count']}/{progress['total_items']} ì²˜ë¦¬ë¨")
                product_ids = progress['remaining_items']
                self.stats.update(progress.get('stats', {}))
                
                if not product_ids:
                    logger.info("âœ… ëª¨ë“  ìƒí’ˆ ì²˜ë¦¬ ì™„ë£Œ")
                    return {'stats': self.stats, 'results': self.results}
                    
                logger.info(f"ğŸ”„ ë‚¨ì€ {len(product_ids)}ê°œ ìƒí’ˆë¶€í„° ì¬ì‹œì‘")
            else:
                logger.info("ğŸ“‚ ì´ì „ ì§„í–‰ ìƒí™©ì´ ì—†ì–´ ì²˜ìŒë¶€í„° ì‹œì‘")
        
        if 'total' not in self.stats or self.stats['total'] == 0:
            self.stats['total'] = len(product_ids)
            
        logger.info(f"ğŸš€ í¬ë¡¤ë§ ì‹œì‘ - ì´ {len(product_ids)}ê°œ ìƒí’ˆ")
        
        start_time = time.time()
        
        async with async_playwright() as p:
            logger.info("ğŸŒ ë¸Œë¼ìš°ì € ì‹œì‘ ì¤‘...")
            
            # Chromium ë¸Œë¼ìš°ì € ì‹œì‘ (í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ)
            browser = await p.chromium.launch(
                headless=False,
                args=[
                    '--no-sandbox',
                    '--disable-blink-features=AutomationControlled',
                    '--disable-web-security',
                    '--disable-features=VizDisplayCompositor'
                ]
            )
            
            try:
                # KeyboardInterrupt í•¸ë“¤ë§ì„ ìœ„í•œ ì‹ í˜¸ ì„¤ì •
                import signal
                
                def signal_handler(signum, frame):  # pylint: disable=unused-argument
                    self.user_interrupted = True
                    logger.warning("âš ï¸  ì‚¬ìš©ìê°€ í¬ë¡¤ë§ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤. í˜„ì¬ê¹Œì§€ì˜ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤...")
                
                signal.signal(signal.SIGINT, signal_handler)
                
                context = await self.create_browser_context(browser)
                
                # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ ì‹¤í–‰ ì œí•œ
                semaphore = asyncio.Semaphore(self.max_concurrent)
                
                processed_items = []
                
                # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì•„ì´í…œ ì¶”ì ìš©
                current_processing_item = None
                
                async def crawl_with_semaphore(product_id: str):
                    nonlocal current_processing_item
                    
                    # ì¤‘ë‹¨ ì‹ í˜¸ í™•ì¸
                    if self.user_interrupted:
                        return
                        
                    async with semaphore:
                        current_processing_item = product_id  # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì•„ì´í…œ ì„¤ì •
                        
                        try:
                            result = await self.check_product_availability(context, product_id)
                            
                            # ì¤‘ë‹¨ ì‹ í˜¸ í™•ì¸
                            if self.user_interrupted:
                                # ë¹„ì •ìƒ ì¤‘ë‹¨ - í˜„ì¬ ì•„ì´í…œì„ ë‹¤ì‹œ ì²˜ë¦¬í•˜ë„ë¡ ë‚¨ê²¨ë‘ê¸°
                                return
                            
                            # ì •ìƒ ì²˜ë¦¬ ì™„ë£Œ
                            processed_items.append(product_id)
                            current_processing_item = None  # ì²˜ë¦¬ ì™„ë£Œ
                            
                            if result:
                                self.results.append(result)
                                if result.get('status') == 'timeout':
                                    # íƒ€ì„ì•„ì›ƒì€ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬
                                    self.stats['failed'] += 1
                                else:
                                    self.stats['success'] += 1
                            else:
                                self.stats['failed'] += 1
                            
                            # ì¤‘ê°„ ì €ì¥ (10ê°œë§ˆë‹¤)
                            if len(processed_items) % 10 == 0:
                                await self.save_results()
                                await self.save_progress(product_ids, processed_items)
                                
                        except Exception as e:
                            logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                            # ì˜¤ë¥˜ ë°œìƒ ì‹œë„ í˜„ì¬ ì•„ì´í…œì„ ë‹¤ì‹œ ì²˜ë¦¬í•˜ë„ë¡ ë‚¨ê²¨ë‘ê¸°
                
                # ëª¨ë“  ìƒí’ˆ í¬ë¡¤ë§ (ìˆœì°¨ ì²˜ë¦¬) - ì¤‘ë‹¨ ì‹ í˜¸ í™•ì¸
                try:
                    for i, pid in enumerate(product_ids):
                        # ì¤‘ë‹¨ ì‹ í˜¸ í™•ì¸
                        if self.user_interrupted:
                            remaining_count = len(product_ids) - i
                            logger.warning(f"âš ï¸ ì‚¬ìš©ì ì¤‘ë‹¨ìœ¼ë¡œ ë‚¨ì€ {remaining_count}ê°œ ì‘ì—… ì¤‘ë‹¨")
                            break
                            
                        # ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
                        await crawl_with_semaphore(pid)
                        
                        # ì²˜ë¦¬ í›„ ì¤‘ë‹¨ ì‹ í˜¸ ì¬í™•ì¸
                        if self.user_interrupted:
                            break
                            
                except KeyboardInterrupt:
                    self.user_interrupted = True
                    logger.warning("âš ï¸  KeyboardInterrupt ì‹ í˜¸ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.")
                
                # ì¤‘ë‹¨ëœ ê²½ìš° ì¦‰ì‹œ ì§„í–‰ ìƒí™© ì €ì¥
                if self.user_interrupted:
                    await self.save_results()
                    await self.save_progress(product_ids, processed_items, current_processing_item)
                    
                    logger.info(f"ğŸ’¾ ì‚¬ìš©ì ì¤‘ë‹¨ - ì§„í–‰ ìƒí™© ì €ì¥ë¨: {len(processed_items)}/{len(product_ids)} ì²˜ë¦¬ ì™„ë£Œ")
                    if current_processing_item:
                        logger.info(f"ğŸ”„ í˜„ì¬ ì²˜ë¦¬ ì¤‘ì´ë˜ ì•„ì´í…œ {current_processing_item}ì´ ë‹¤ìŒ ì‹¤í–‰ ì‹œ ì¬ì²˜ë¦¬ë©ë‹ˆë‹¤.")
                
                await context.close()
                
            finally:
                await browser.close()
        
        # ìµœì¢… ì €ì¥ (ì¤‘ë‹¨ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ)
        if not self.user_interrupted:
            await self.save_results()
        
        total_time = time.time() - start_time
        
        # ìµœì¢… í†µê³„
        logger.info("=" * 60)
        if self.user_interrupted:
            logger.warning("âš ï¸ ì‚¬ìš©ì ì¤‘ë‹¨ìœ¼ë¡œ í¬ë¡¤ë§ ì¤‘ë‹¨!")
        else:
            logger.info("ğŸ í¬ë¡¤ë§ ì™„ë£Œ!")
        logger.info(f"ğŸ“Š ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
        logger.info(f"ğŸ“ˆ ì„±ê³µë¥ : {self.stats['success']}/{self.stats['total']} ({self.stats['success']/self.stats['total']*100:.1f}%)")
        logger.info(f"âœ… ì„±ê³µ: {self.stats['success']}")
        logger.info(f"âŒ ì‹¤íŒ¨: {self.stats['failed']}")
        logger.info(f"ğŸ’¾ ê²°ê³¼ íŒŒì¼: {self.output_file}")
        logger.info("=" * 60)
        
        return {
            'stats': self.stats,
            'total_time': total_time,
            'results': self.results,
            'user_interrupted': self.user_interrupted,
            'interrupted': self.user_interrupted
        }

async def main():
    """í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸"""
    import sys
    
    # ëª…ë ¹í–‰ ì¸ìë¡œ resume ì˜µì…˜ ë°›ê¸°
    resume = '--resume' in sys.argv or '-r' in sys.argv
    
    test_ids = ["A123456", "A789012"]  # í…ŒìŠ¤íŠ¸ìš© ID
    
    crawler = OliveYoungCrawler(
        max_concurrent=2,
        delay_range=(2, 4),
        output_file="test_results.json"
    )
    
    if resume:
        print("ğŸ”„ ì´ì „ ì§„í–‰ ìƒí™©ì—ì„œ í¬ë¡¤ë§ì„ ì¬ì‹œì‘í•©ë‹ˆë‹¤...")
    else:
        print("ğŸš€ ìƒˆë¡œìš´ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    results = await crawler.crawl_products(test_ids, resume_from_progress=resume)
    
    if results['interrupted']:
        print(f"\nâš ï¸  í¬ë¡¤ë§ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤:")
        if results['user_interrupted']:
            print("   - ì‚¬ìš©ì ì¤‘ë‹¨")
        print(f"\nğŸ“Š ì§„í–‰ ìƒí™©: {results['stats']}")
        print(f"\nğŸ”„ ì¬ì‹œì‘í•˜ë ¤ë©´: python {sys.argv[0]} --resume")
    else:
        print(f"\nâœ… í¬ë¡¤ë§ ì™„ë£Œ: {results['stats']}")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nâš ï¸  í¬ë¡¤ë§ì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("ğŸ”„ ì¬ì‹œì‘í•˜ë ¤ë©´: python crawler.py --resume")